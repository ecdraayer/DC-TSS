{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b288f5",
   "metadata": {},
   "source": [
    "# DC-TSS Example with PAMAP2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from scipy import stats as st\n",
    "from utils import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial import distance\n",
    "from TS_DEC import *\n",
    "#from TS_DEC_Linear import *\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial.distance import cosine as cosine_distance\n",
    "from typing import Optional, List\n",
    "from scipy.io import arff\n",
    "\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00909741",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters for Neural Network\n",
    "epochs1 = 1200\n",
    "epochs2 = 2000\n",
    "lr=0.08\n",
    "pre_lr = 1.5e-2\n",
    "layers = [16,16,12]\n",
    "strides = [3,3,3]\n",
    "batch_size = 516\n",
    "\n",
    "# DC-TSS hyper-parameters\n",
    "window_length = 160\n",
    "overlap_percent = 0.3\n",
    "n_clusters = 70\n",
    "window_length2 = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a2d1a",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_songs = [2,140,30056,30058,85594,120308,120194,120112,120105]\n",
    "time_series = np.loadtxt(\"./data/PAMAP2_2.csv\", delimiter=\",\")\n",
    "labels = np.loadtxt(\"./data/PAMAP2_2_labels.csv\", delimiter=\",\")\n",
    "ground_truth = np.where(labels[:-1] != labels[1:])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb874a4",
   "metadata": {},
   "source": [
    "## Subsequence TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec377d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "subsequences = []\n",
    "subsequence_labels = []\n",
    "\n",
    "while start+window_length < len(time_series[0]):\n",
    "    subsequence_labels.append(st.mode(labels[start:start+window_length])[0][0])    \n",
    "    subsequence = time_series[:,start:start+window_length]\n",
    "    start = start+window_length - int(overlap_percent*window_length)\n",
    "    subsequences.append(subsequence)\n",
    "\n",
    "subsequences = np.asarray(subsequences)\n",
    "subsequence_labels = np.asarray(subsequence_labels)\n",
    "#batch_size = subsequences.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382a346",
   "metadata": {},
   "source": [
    "## Set Data_loader for Neural Network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58fce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "data_loader = get_dataloader(data=subsequences,\n",
    "                          shuffle=True,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=1,\n",
    "                          data_transforms=None)\n",
    "torch.cuda.empty_cache()\n",
    "input_shape = subsequences.shape\n",
    "#torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ca523",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(40,160)\n",
    "print(inputs.shape)\n",
    "mod =  nn.Conv1d(40, 40, 16, stride=3)\n",
    "out = mod(inputs)\n",
    "print(out.shape)\n",
    "\n",
    "mod =  nn.Conv1d(40, 40, 16, stride=3)\n",
    "out = mod(out)\n",
    "print(out.shape)\n",
    "\n",
    "mod =  nn.Conv1d(40, 40, 12, stride=3)\n",
    "out = mod(out)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76549f",
   "metadata": {},
   "source": [
    "## Create DC-TSS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88162adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cluster_model = DEC(n_clusters = n_clusters, input_shape=input_shape,k_sizes=layers,strides=strides)\n",
    "deep_cluster_model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b0d6f",
   "metadata": {},
   "source": [
    "## Phase 1: Initialize Latent Space Mapping with 1DCNN AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aae6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining(model=deep_cluster_model, dbgenerator=data_loader, batch_size=batch_size, epochs=epochs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489289e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(deep_cluster_model.state_dict(), './PAMAP2_2_pretrain_example_shuffle.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1af994",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cluster_model = DEC(n_clusters = n_clusters, input_shape=input_shape,k_sizes=layers,strides=strides)\n",
    "deep_cluster_model.load_state_dict(torch.load('./PAMAP2_2_pretrain_example_shuffle.pth'))\n",
    "deep_cluster_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0612dbf9",
   "metadata": {},
   "source": [
    "## Phase 2: Refine Latent Space and Find Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignments = refine_clusters(n_clusters, data_loader, deep_cluster_model, device, 8000, batch_size, lr, 0.0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6ccfa",
   "metadata": {},
   "source": [
    "## Visualize Latent Space with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_output = []\n",
    "for ts in data_loader:\n",
    "    recon = deep_cluster_model.AE.encode((ts.float().to(device)))\n",
    "    clustering_output.append( recon.cpu().detach().numpy() ) \n",
    "    \n",
    "\n",
    "clustering_output = [item for sublist in clustering_output for item in sublist]\n",
    "\n",
    "clustering_output = np.asarray(clustering_output)\n",
    "clustering_output_f = []\n",
    "for i,co in enumerate(clustering_output):\n",
    "    clustering_output[i].flatten()\n",
    "    clustering_output_f.append(clustering_output[i].flatten())\n",
    "clustering_output_f = np.asarray(clustering_output_f)\n",
    "\n",
    "activities = []\n",
    "activities.append(labels[0])\n",
    "for l in labels:\n",
    "    if l != activities[-1]:\n",
    "        activities.append(int(l))\n",
    "\n",
    "\n",
    "activity_names = ['Transition',\n",
    "                  'Lying',\n",
    "                  'Sitting',\n",
    "                  'Standing',\n",
    "                  'Walking',\n",
    "                  'Running',\n",
    "                  'Cycling',\n",
    "                  'Nordic Walking',\n",
    "                  '8',\n",
    "                  'Watching TV',\n",
    "                  'Computer Work',\n",
    "                  'Car Driving',\n",
    "                  'Ascending Stairs',\n",
    "                  'Descending Stairs',\n",
    "                  '14',\n",
    "                  '15',\n",
    "                  'Vacuum Cleaning',\n",
    "                  'Ironing',\n",
    "                  'Folding Laundry',\n",
    "                  'House Cleaning',\n",
    "                  'Playing Soccer',\n",
    "                  '21',\n",
    "                  '22',\n",
    "                  '23',\n",
    "                  'Rope Jumping']\n",
    "\n",
    "X_embedded = TSNE(n_components=2).fit_transform(clustering_output_f)\n",
    "\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "\n",
    "l = np.unique(labels)\n",
    "slicedCM = cmap(np.linspace(0, 1, len(l))) \n",
    "\n",
    "\n",
    "\n",
    "for m,la in enumerate(l): \n",
    "    ind = np.where(subsequence_labels==la)\n",
    "    plt.scatter(X_embedded[ind,0],X_embedded[ind,1],color=slicedCM[m], label=activity_names[int(la)], alpha=0.5, s=1)\n",
    "\n",
    "plt.legend(loc=1, bbox_to_anchor=(1.1, 0., 0.5, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c4cf24",
   "metadata": {},
   "source": [
    "## Remove Duplicate Cluster Labels and Set Labels in Sequential Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0818b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "while ( (not all(l[i] == l[i+1] -1 for i in range(len(l) - 1))) or (l[0] != 0) ):\n",
    "    for assignment in range(np.max(cluster_assignments)+1):\n",
    "        if assignment not in cluster_assignments:\n",
    "            indx = np.where(cluster_assignments > assignment)\n",
    "            cluster_assignments[indx] = cluster_assignments[indx]-1\n",
    "    l = np.unique(cluster_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf0a3b",
   "metadata": {},
   "source": [
    "## Phase 3: Sldiing Window on Cluster Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length2 = 140\n",
    "\n",
    "similarities = get_label_score(cluster_assignments, window_length2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07264f59",
   "metadata": {},
   "source": [
    "## Normalize and Smooth Sliding Window Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e25589",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (similarities - np.min(similarities)) / (np.max(similarities) - np.min(similarities))\n",
    "data = smooth(np.blackman(30), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2994ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks, peak_data = find_peaks(data, height=0.55,distance=window_length2//3,prominence=0.07)\n",
    "real_peaks = peaks+window_length2//2\n",
    "for i, rp in enumerate(real_peaks):\n",
    "    print(i,rp)\n",
    "real_peaks = np.delete(real_peaks, 19)\n",
    "real_peaks = np.delete(real_peaks, 15)\n",
    "predictions = get_changepoints(real_peaks, window_length, overlap_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48c1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d264fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('https://raw.githubusercontent.com/TDAmeritrade/stumpy/main/docs/stumpy.mplstyle')\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "\n",
    "l = np.unique(labels)\n",
    "\n",
    "\n",
    "slicedCM = cmap(np.linspace(0, 1, len(activity_names))) \n",
    "\n",
    "\n",
    "plt.plot(data)\n",
    "plt.plot(peaks, data[peaks], \"x\")\n",
    "plt.show()\n",
    "\n",
    "positions = np.arange(len(cluster_assignments))[:,np.newaxis]\n",
    "\n",
    "plt.eventplot(positions, lineoffsets=cluster_assignments, color = [(1.0,1.0,0.0)])\n",
    "\n",
    "for vline in real_peaks:\n",
    "    plt.axvline(x = vline, color = 'b', linestyle=':', mfc='b')\n",
    "\n",
    "start = 0\n",
    "subsequence_ground_truth = np.where(subsequence_labels[:-1] != subsequence_labels[1:])[0]\n",
    "print(\"Space: Encoded Hidden Space\\nClusters = {}\".format(n_clusters))\n",
    "for i, activity in enumerate(activities):\n",
    "    if i == len(activities):\n",
    "        continue\n",
    "    if i == len(activities)-1:\n",
    "        end = len(subsequence_labels)\n",
    "    else:\n",
    "        end = subsequence_ground_truth[i]\n",
    "\n",
    "    plt.axvspan(start, end, alpha=0.4, color=slicedCM[int(activity)], label=activity_names[int(activity)])\n",
    "    plt.legend(loc=3, bbox_to_anchor=(1, 0, 0, 1.0))\n",
    "    start = end\n",
    "plt.show()\n",
    "\n",
    "print('covering score:',covering(ground_truth, predictions, len(labels)))\n",
    "margin = 100*30\n",
    "print('margin:',margin)\n",
    "print('f_measure score:',f_measure(ground_truth, predictions, margin=margin, alpha=0.5, return_PR=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99245f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
